{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q py-feat # Instalamos la librería py-feat","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-15T10:47:08.604695Z","iopub.execute_input":"2022-05-15T10:47:08.605056Z","iopub.status.idle":"2022-05-15T10:47:32.047047Z","shell.execute_reply.started":"2022-05-15T10:47:08.604956Z","shell.execute_reply":"2022-05-15T10:47:32.045783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport errno\nimport cv2\nimport glob\n\nfrom feat.detector import Detector\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-15T10:49:57.11022Z","iopub.execute_input":"2022-05-15T10:49:57.110563Z","iopub.status.idle":"2022-05-15T10:50:02.947089Z","shell.execute_reply.started":"2022-05-15T10:49:57.110524Z","shell.execute_reply":"2022-05-15T10:50:02.945582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funciones.\n\ndef process_data(path, size): # Default\n    print('Procesando datos...')\n    \n    #-Airán: Contador de elementos procesados\n    elementos_procesados = 0\n    \n    #-Airan: Información y muestra 1º elemento\n    first = True\n    result_1 = 'NaN'\n    fex_1 = 'NaN'\n    \n    # Instancia del detector con modelos por defecto\n    #detector = Detector()\n    detector = Detector(emotion_model = \"fer\") # Modelo fer\n    \n    sub_paths = ['Train', 'Validation'] #-Airan: Sub_Path\n    \n    # Carpetas con muestras\n    folders = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n    \n    # Etiquetas del clasificador\n    switch_labels = [0, 1, 2, 3, 6, 4, 5] # indice = classlabels ; value = py_feat_labels\n    classlabels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'] # Folders\n    py_feat_labels = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise' , 'neutral'] # Py-feat\n    \n    y = []\n    y_pred = []\n    \n    y_train = []\n    y_pred_train = []\n    \n    y_validation = []\n    y_pred_validation = []\n    \n    n_clases = 0\n    for fex in folders:\n        \n        for sub_path in sub_paths: #-Airan: Obtener todo el dataset: Train, Validation\n            \n            folder = os.path.join((path + sub_path), fex)\n            \n            for file_name in os.listdir(folder):\n\n                # Asume imágenes en formato png\n                if file_name.endswith('.png'):\n                    \n                    elementos_procesados += 1\n                    \n                    #-Airan: Ruta completa imagen, \"detect_image\" sólo admite path.\n                    abs_path = os.path.join(folder, file_name)\n                    \n                    #-- Código\n                    # FEX de imagen\n                    result = detector.detect_image(abs_path)\n                    # Obtiene el dataframe con únicamente informacion de emociones\n                    fex_ = result.emotions()\n                    #print(fex_)\n\n                    if fex_.iloc[0].isnull().all() == False: # Garantizamos detección de caras.\n                        #-Airán: Información y muestra 1º elemento\n                        if first:\n                            fex_1 = fex_\n                            result_1 = result\n                            first = False\n                        \n                        #--- Conjunto completo.\n                        y.append(switch_labels[n_clases])\n                        y_pred.append(py_feat_labels.index(fex_.idxmax(axis=1).tolist()[0]))\n                        #--- Conjunto Train.\n                        if sub_path == sub_paths[0]:\n                            y_train.append(switch_labels[n_clases])\n                            y_pred_train.append(py_feat_labels.index(fex_.idxmax(axis=1).tolist()[0]))\n                        #--- Conjunto Validation.\n                        if sub_path == sub_paths[1]:\n                            y_validation.append(switch_labels[n_clases])\n                            y_pred_validation.append(py_feat_labels.index(fex_.idxmax(axis=1).tolist()[0]))\n                        \n        n_clases += 1\n    \n    print('\\nINFORMACIÓN DATASET')\n    print('Número de carpetas:', len(folders))\n    print('Número de clases:', len(py_feat_labels))\n    print('Categoría Predicha:',fex_1.idxmax(axis=1))\n    result_1.plot_detections()\n    print('Tamaño de la imagen:',size)\n    print('Elementos procesados:',elementos_procesados)\n    \n    print('FIN Procesando datos.')\n    return y, y_pred, y_train, y_pred_train, y_validation, y_pred_validation","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:59:06.364572Z","iopub.execute_input":"2022-05-15T11:59:06.364958Z","iopub.status.idle":"2022-05-15T11:59:06.386006Z","shell.execute_reply.started":"2022-05-15T11:59:06.364923Z","shell.execute_reply":"2022-05-15T11:59:06.384943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--- EXPERIMENTACIÓN ---\n#--- Tamaños de imágenes: (143, 181), (71, 90), (35, 45), (17, 22)\n#--- DataSet: (143, 181)\nswitch_labels = [0, 1, 2, 3, 6, 4, 5] # indice = classlabels ; value = py_feat_labels\npy_feat_labels = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise' , 'neutral'] # Py-feat\n\nprint('--- INICIO SIMULACIÓN ---')\n\n#------------------------ SIMULACION 1 -------------\nprint('\\nSimulación: 1')\ny, y_pred, y_train, y_pred_train, y_validation, y_pred_validation = process_data('../input/sfewnew/SFEW/', (143, 181))\n#--- Información de los resultados obtenidos:\nprint(\"\\nPy-Feat FER Metrics\") # Reconocimiento Facial de Emociones.\n#--- Información Conjunto Completo:\nprint(\"\\nInformación Conjunto Completo\")\nprecision_score(y, y_pred, average='weighted')\nrecall_score(y, y_pred, average='weighted')\nprint(classification_report(y, y_pred, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y, y_pred, labels=range(len(switch_labels))))\n#--- Información Conjunto Train:\nprint(\"\\nInformación Conjunto Train\")\nprecision_score(y_train, y_pred_train, average='weighted')\nrecall_score(y_train, y_pred_train, average='weighted')\nprint(classification_report(y_train, y_pred_train, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_train, y_pred_train, labels=range(len(switch_labels))))\n#--- Información Conjunto Validation:\nprint(\"\\nInformación Conjunto Validation\")\nprecision_score(y_validation, y_pred_validation, average='weighted')\nrecall_score(y_validation, y_pred_validation, average='weighted')\nprint(classification_report(y_validation, y_pred_validation, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_validation, y_pred_validation, labels=range(len(switch_labels))))\n\n#------------------------ SIMULACION 2 -------------\nprint('\\nSimulación: 2')\ny, y_pred, y_train, y_pred_train, y_validation, y_pred_validation = process_data('../input/sfewnew/SFEW_17x22/', (17, 22))\n#--- Información de los resultados obtenidos:\nprint(\"\\nPy-Feat FER Metrics\") # Reconocimiento Facial de Emociones.\n#--- Información Conjunto Completo:\nprint(\"\\nInformación Conjunto Completo\")\nprecision_score(y, y_pred, average='weighted')\nrecall_score(y, y_pred, average='weighted')\nprint(classification_report(y, y_pred, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y, y_pred, labels=range(len(switch_labels))))\n#--- Información Conjunto Train:\nprint(\"\\nInformación Conjunto Train\")\nprecision_score(y_train, y_pred_train, average='weighted')\nrecall_score(y_train, y_pred_train, average='weighted')\nprint(classification_report(y_train, y_pred_train, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_train, y_pred_train, labels=range(len(switch_labels))))\n#--- Información Conjunto Validation:\nprint(\"\\nInformación Conjunto Validation\")\nprecision_score(y_validation, y_pred_validation, average='weighted')\nrecall_score(y_validation, y_pred_validation, average='weighted')\nprint(classification_report(y_validation, y_pred_validation, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_validation, y_pred_validation, labels=range(len(switch_labels))))\n\n#------------------------ SIMULACION 3 -------------\nprint('\\nSimulación: 3')\ny, y_pred, y_train, y_pred_train, y_validation, y_pred_validation = process_data('../input/sfewnew/SFEW_35x45/', (35, 45))\n#--- Información de los resultados obtenidos:\nprint(\"\\nPy-Feat FER Metrics\") # Reconocimiento Facial de Emociones.\n#--- Información Conjunto Completo:\nprint(\"\\nInformación Conjunto Completo\")\nprecision_score(y, y_pred, average='weighted')\nrecall_score(y, y_pred, average='weighted')\nprint(classification_report(y, y_pred, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y, y_pred, labels=range(len(switch_labels))))\n#--- Información Conjunto Train:\nprint(\"\\nInformación Conjunto Train\")\nprecision_score(y_train, y_pred_train, average='weighted')\nrecall_score(y_train, y_pred_train, average='weighted')\nprint(classification_report(y_train, y_pred_train, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_train, y_pred_train, labels=range(len(switch_labels))))\n#--- Información Conjunto Validation:\nprint(\"\\nInformación Conjunto Validation\")\nprecision_score(y_validation, y_pred_validation, average='weighted')\nrecall_score(y_validation, y_pred_validation, average='weighted')\nprint(classification_report(y_validation, y_pred_validation, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_validation, y_pred_validation, labels=range(len(switch_labels))))\n\n#------------------------ SIMULACION 4 -------------\nprint('\\nSimulación: 4')\ny, y_pred, y_train, y_pred_train, y_validation, y_pred_validation = process_data('../input/sfewnew/SFEW_71x90/', (71, 90))\n#--- Información de los resultados obtenidos:\nprint(\"\\nPy-Feat FER Metrics\") # Reconocimiento Facial de Emociones.\n#--- Información Conjunto Completo:\nprint(\"\\nInformación Conjunto Completo\")\nprecision_score(y, y_pred, average='weighted')\nrecall_score(y, y_pred, average='weighted')\nprint(classification_report(y, y_pred, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y, y_pred, labels=range(len(switch_labels))))\n#--- Información Conjunto Train:\nprint(\"\\nInformación Conjunto Train\")\nprecision_score(y_train, y_pred_train, average='weighted')\nrecall_score(y_train, y_pred_train, average='weighted')\nprint(classification_report(y_train, y_pred_train, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_train, y_pred_train, labels=range(len(switch_labels))))\n#--- Información Conjunto Validation:\nprint(\"\\nInformación Conjunto Validation\")\nprecision_score(y_validation, y_pred_validation, average='weighted')\nrecall_score(y_validation, y_pred_validation, average='weighted')\nprint(classification_report(y_validation, y_pred_validation, target_names=py_feat_labels))\nprint(\"Confussion matrix:\")\nprint(confusion_matrix(y_validation, y_pred_validation, labels=range(len(switch_labels))))\n\nprint('--- FIN SIMULACIÓN ---')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:59:13.005237Z","iopub.execute_input":"2022-05-15T11:59:13.005519Z","iopub.status.idle":"2022-05-15T12:29:15.461056Z","shell.execute_reply.started":"2022-05-15T11:59:13.00549Z","shell.execute_reply":"2022-05-15T12:29:15.459805Z"},"trusted":true},"execution_count":null,"outputs":[]}]}